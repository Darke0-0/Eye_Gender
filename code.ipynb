{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # Deep Learning Tool\n",
    "from sklearn.model_selection import train_test_split # For splitting the data into train and validation set\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('eye_gender_data/Training_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting male-female to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def male_female(x):\n",
    "    if x == 'male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"eye_gender_data/Training_set.csv\") # loading the labels\n",
    "file_paths = [[fname, 'eye_gender_data/train/' + fname] for fname in labels['filename']]\n",
    "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
    "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
    "\n",
    "x_train = [] # initialize an empty numpy array\n",
    "image_size = 53 # image size taken is 100 here. one can take other size too\n",
    "for i in range(len(train_data)):\n",
    "\n",
    "    img_array = cv2.imread(train_data['filepaths'][i], cv2.IMREAD_GRAYSCALE) # converting the image to gray scale\n",
    "\n",
    "    new_img_array = cv2.resize(img_array,( image_size, image_size)) # resizing the image array\n",
    "    x_train.append(new_img_array)\n",
    "x_train = np.asarray(x_train, dtype=int)\n",
    "x_train = x_train.reshape(9220,53,53,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train.apply(lambda x: male_female(x.label),axis =1 )\n",
    "y_train = train['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_train = 2*x_train - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input shape\n",
    "INPUT_SHAPE = (53, 53, 1)\n",
    "\n",
    "# define sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "# define conv-pool layers - set 1\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1),\n",
    "activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "# define conv-pool layers - set 2\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1),\n",
    "activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# add flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# add dense layers with some dropout\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "# add output layer\n",
    "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# view model layers\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "260/260 [==============================] - 9s 35ms/step - loss: 0.4745 - accuracy: 0.7674 - val_loss: 0.3576 - val_accuracy: 0.8471\n",
      "Epoch 2/5\n",
      "260/260 [==============================] - 9s 35ms/step - loss: 0.3226 - accuracy: 0.8594 - val_loss: 0.3105 - val_accuracy: 0.8688\n",
      "Epoch 3/5\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2523 - accuracy: 0.8976 - val_loss: 0.2950 - val_accuracy: 0.8731\n",
      "Epoch 4/5\n",
      "260/260 [==============================] - 7s 27ms/step - loss: 0.2113 - accuracy: 0.9167 - val_loss: 0.2206 - val_accuracy: 0.9089\n",
      "Epoch 5/5\n",
      "260/260 [==============================] - 9s 33ms/step - loss: 0.1731 - accuracy: 0.9323 - val_loss: 0.2510 - val_accuracy: 0.8915\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2,\n",
    "restore_best_weights=True,\n",
    "verbose=1)\n",
    "\n",
    "history = model.fit(x_train,\n",
    "y_train,\n",
    "batch_size=32,\n",
    "callbacks=[es_callback],\n",
    "validation_split=0.1, epochs=EPOCHS,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"eye_gender_data/Testing_set.csv\") # loading the labels\n",
    "file_paths = [[fname, 'eye_gender_data/test/' + fname] for fname in labels['filename']]\n",
    "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
    "test_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
    "\n",
    "x_test = [] # initialize an empty numpy array\n",
    "image_size = 53 # image size taken is 100 here. one can take other size too\n",
    "for i in range(len(test_data)):\n",
    "\n",
    "    img_array = cv2.imread(test_data['filepaths'][i], cv2.IMREAD_GRAYSCALE) # converting the image to gray scale\n",
    "\n",
    "    new_img_array = cv2.resize(img_array,( image_size, image_size)) # resizing the image array\n",
    "    x_test.append(new_img_array)\n",
    "x_test = np.asarray(x_test, dtype=int)\n",
    "x_test = x_test.reshape(2305,53,53,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255\n",
    "x_test = 2*x_test - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "prediction_labels = np.argmax(predictions, axis=1)\n",
    "pred = list(prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting from 0-1 to male-female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pred)):\n",
    "    if pred[i] == 0:\n",
    "        pred[i] = 'male'\n",
    "    else:\n",
    "        pred[i] = 'female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'label': pred}) # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
    "res.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
